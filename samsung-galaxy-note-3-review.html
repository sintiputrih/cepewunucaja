<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Performance: CPU, GPU, NAND &amp;amp; USB 3.0 | JamBlog</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="CPU Performance The original Note I played with was based on Qualcomm’s APQ8060 platform with MDM9200 baseband (the so-called Fusion 2 platform) and was for its time a pretty awesome piece of kit, combining LTE and a dual core SoC. The Note 2 I played with next was based on Samsung’s own Exynos 4412 SoC with quad core Cortex A9 at 1.6 GHz and Mali–400MP4 GPU. For the Note 3, I’m looking at a T-Mobile variant (SM-N900T if you want to be exact about it) which means it includes a Snapdragon 800 SoC, and Samsung has gone for the 2."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>JamBlog</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>Performance: CPU, GPU, NAND &amp;amp; USB 3.0</h1><div><strong>Publish date: </strong>2024-09-03</div><h2>CPU Performance</h2><p>The original Note I played with was based on Qualcomm’s APQ8060 platform with MDM9200 baseband (the so-called Fusion 2 platform) and was for its time a pretty awesome piece of kit, combining LTE and a dual core SoC. The Note 2 I played with next was based on Samsung’s own Exynos 4412 SoC with quad core Cortex A9 at 1.6 GHz and Mali–400MP4 GPU. For the Note 3, I’m looking at a T-Mobile variant (SM-N900T if you want to be exact about it) which means it includes a Snapdragon 800 SoC, and Samsung has gone for the 2.3 GHz bin (really 2.265 GHz rounded up). Inside are 4 Krait 400 CPUs running at up to 2.3 GHz, and Adreno 330 graphics at up to 450 MHz, all built on TSMC’s 28nm HPM HK-MG process.</p><p>I should note that this is MSM8974 and not <a href=#>MSM8974AB</a> which oddly enough one of Qualcomm’s customers already announced (Xiaomi for the Mi3) which boosts GPU clocks up to 550 MHz and the LPDDR3 memory interface up to 933 MHz, among a few other changes. I’ve confirmed that GPU clocks on the Note 3 are indeed maxing out at 450 MHz, and quite honestly it’s a bit early for 8974AB in the first place, though it wouldn’t surprise me to see Samsung eventually get that faster bin at some point and put it in something.</p><p>&nbsp;</p><p>I should mention that the Note 3 (like many other Android devices - SGS4, HTC One) detects certain benchmarks and ensures CPU frequencies are running at max while running them, rather than relying on the benchmark workload to organically drive DVFS to those frequencies. Max supported CPU frequency is never exceeded in this process, the platform simply primes itself for running those tests as soon as they're detected. The impact is likely small since most of these tests should drive CPU frequencies to their max state regardless (at least on the CPU side), but I'm going to make it a point to call out this behavior whenever I see it from now on. Make no mistake, this is cheating plain and simple. It's a stupid cheat that most Android OEMs seem to be ok with and honestly isn't worth the effort.&nbsp;<strong>Update</strong>: Of our CPU tests&nbsp;<a href=#>only AndEBench is affected exclusively by Samsung's optimizations</a>, the performance gain appears to be around 4%. Vellamo is gamed by all of the Snapdragon 800 platforms we have here (ASUS, LG and Samsung). None of this is ok and we want it to stop, but I'm assuming it's not going to. In light of that we're working with all of the benchmark vendors we use to detect and disable any cheats as we find them. We have renamed versions of nearly all of our benchmarks and will have uniquely named versions of all future benchmarks we use. We'll be repopulating our Bench data where appropriate.</p><p>CPU performance is honestly excellent. The Galaxy Note 3 is more or less the fastest Android smartphone we've tested up to this point. In the situations where we can do cross platform (OS/browser) comparisons, it isn't quite as fast as the iPhone 5s but in some cases it comes close.</p><p align=center><img alt="AndEBench - Java" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58407.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="AndEBench - Native" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58408.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="SunSpider Javascript Benchmark 1.0 - Stock Browser" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58440.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Google Octane Benchmark v1" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58433.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Mozilla Kraken Benchmark - 1.1" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58434.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Browsermark 2.0" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58414.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Vellamo Benchmark - 2.0" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58441.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Vellamo Benchmark - 2.0" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58442.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><h2>GPU Performance</h2><p>Samsung definitely likes to win, and the Galaxy Note 3 walks away with the GPU performance crown in literally every single offscreen test we've got here. The onscreen tests are obviously governed by display resolution, but all things being equal the Note 3 manages to get the edge over the PowerVR G6430 in Apple's iPhone 5s. It's also interesting to note that the Galaxy Note 3 appears to outperform all other Snapdragon 800 smartphones we've tested thus far. There's a couple of potential explanations here. First, the Galaxy Note 3 is using newer drivers than any of the other S800 platforms we've tested:</p><p>Note 3: 04.03.00.125.077<br>Padfone: 04.02.02.050.116<br>G2: 4.02.02.050.141</p><p>Secondly, it's unclear how much the manual CPU DVFS setting upon benchmark launch is influencing things - although I suspect it's significant in the case of something like 3DMark.&nbsp;</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/7376/Screenshot_2013-09-24-13-31-10_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Finally each manufacturer has the ability to define their own thermal limits/governor behavior, it could simply be that Samsung is a bit more aggressive on this front. We honestly haven't had enough time to dig into finding out exactly what's going on here (Samsung gave us less than a week to review 3 devices), but the end result are some incredibly quick scores for the Note 3. If I had to guess I'd assume it's actually a combination of all three vectors: drivers, high CPU frequencies and being more lenient with thermals.</p><p><strong>Update:</strong> GFXBench 2.7 isn't affected by any optimizations here, but Basemark X and 3DMark are. We expect the <a href=#>Note 3's performance is inflated by somewhere in the 3 - 10% range</a>. We're working on neutralizing this optimization across our entire suite.</p><p align=center><img alt="GLBenchmark 2.7 - T-Rex HD" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58425.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="GLBenchmark 2.7 - T-Rex HD (Offscreen 1080p)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58426.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="GLBenchmark 2.7 - Egypt HD" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58421.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="GLBenchmark 2.7 - Egypt HD (Offscreen 1080p)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58422.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="3DMark Unlimited - Ice Storm" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58390.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Basemark X - On Screen" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58412.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Basemark X - Off Screen" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58411.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Epic Citadel - Ultra High Quality, 100% Resolution" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58420.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><h2>NAND & USB 3.0 Performance</h2><p>Our Galaxy Note 3 review sample posted some incredible storage performance results, at least compared to all other Android smartphones we've tested. Sequential read and write performance are both class leading - the latter is nearly 2x better than the next fastest phone we've tested. Random read performance is decent, but it's random write performance that's surprising. Unlike the Moto X, the Galaxy Note 3 doesn't rely on a flash-friendly file system to get great random write performance - this is raw eMMC horsepower (if you can call ~600 IOPS that). The result isn't quite as good as what you get out of the Moto X, but it comes very close. Android 4.3 should bring FSTRIM support to the Galaxy Note 3, so as long as you remember to leave around 20% of your storage as free space you should enjoy relatively speedy IO regardless of what you do to the phone.</p><p align=center><img alt="Sequential Read (256KB) Performance" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58437.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Sequential Write (256KB) Performance" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58438.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center>&nbsp;</p><p align=center><img alt="Random Read (4KB) Performance" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58435.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p align=center><img alt="Random Write (4KB) Performance" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph7376/58436.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The Galaxy Note 3 ships with USB 3.0, unfortunately at least in its current state it doesn't seem to get any benefit from the interface. Although the internal eMMC is capable of being read from at ~100MB/s, sustained transfers from the device over adb averaged around 30MB/s regardless of whether or not I connected the Note 3 to a USB 2.0 or 3.0 host.</p><p><strong>Update:</strong> USB 3.0 does work on the Note 3, but only when connected to a Windows PC with USB 3.0. Doing so brings up a new option in the "USB Computer Connection" picker with USB 3.0 as an option. Ticking this alerts you that using USB 3.0 might interfere with calls and data, but then switches over. Connection transfer speed is indeed faster in this mode as well, like you'd expect.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/7376/2013-10-0202.47.51_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a>&nbsp;<a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/7376/2013-10-0220.12.51_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>It only appears on Windows as well, my earlier attempts were on OS X where this popup option never appears.&nbsp;</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZIR0g5Voqpqlo6q7qHnGmqOasKliu7DAxGZqZqqVq7amw45t</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>