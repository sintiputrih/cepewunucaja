<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Compute &amp;amp; Synthetics - The NVIDIA GeForce RTX 2070 Founders Edition Review: Mid-Range Turing, High-E | JamBlog</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="Compute & Synthetics Shifting gears, we'll look at the compute and synthetic aspects of the RTX 2070. Though it has its own GPU in the form of TU106, the hardware resources at hand are similar in progression to what we've seen in TU102 and TU104.
Starting off with GEMM tests, the RTX 2070's tensor cores are pulled into action with half-precision matrix multiplication, though using binaries originally compiled for Volta. Because Turing is backwards compatible and in the same compute capability family as Volta (sm_75 compared to Volta's sm_70), the benchmark continues to work out-of-the-box, though without any Turing optimizations."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>JamBlog</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>Compute &amp;amp; Synthetics - The NVIDIA GeForce RTX 2070 Founders Edition Review: Mid-Range Turing, High-E</h1><div><strong>Publish date: </strong>2024-05-29</div><h2>Compute & Synthetics</h2><p>Shifting gears, we'll look at the compute and synthetic aspects of the RTX 2070. Though it has its own GPU in the form of TU106, the hardware resources at hand are similar in progression to what we've seen in TU102 and TU104.</p><p>Starting off with GEMM tests, the RTX 2070's tensor cores are pulled into action with half-precision matrix multiplication, though using binaries originally compiled for Volta. Because Turing is backwards compatible and in the same compute capability family as Volta (sm_75 compared to Volta's sm_70), the benchmark continues to work out-of-the-box, though without any Turing optimizations.</p><p><img alt="Compute: General Matrix Multiply Half Precision (HGEMM)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101941.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><img alt="Compute: General Matrix Multiply Single Precision (SGEMM)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101942.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>At reference specifications, peak theoretical tensor throughput is around 107.6 TFLOPS for the RTX 2080 Ti, 80.5 TFLOPS for the RTX 2080, and 59.7 TFLOPS for the RTX 2070. Unlike the 89% efficiency with the Titan V's 97.5 TFLOPS, the RTX cards are essentially at half that level, with around 47%, 48%, and 45% efficiency for the RTX 2080 Ti, 2080, and 2070 respectively. A Turing-optimized binary should bring that up, though it is possible that the GeForce RTX cards may not be designed for efficient tensor FP16 operations as opposed to the INT dot-product acceleration. After all, the GeForce RTX cards are for consumers and ostensibly intended for inferencing rather than training, which is the reasoning for the new INT support in Turing tensor cores.</p><p>In terms of SGEMM efficiency though, the RTX 2070 is hitting a ridiculous 97% of its touted 7.5 TFLOPS, though to be fair the reference specifications here are done manually rather with a reference vBIOS. The other two GeForce RTX cards are at similar 90+% levels of efficiency, though a GEMM test like this is specifically designed for maximum utilization.</p><p><img alt="Compute: CompuBench 2.0 - Level Set Segmentation 256" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101943.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Compute: CompuBench 2.0 - N-Body Simulation 1024K" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101944.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><img alt="Compute: CompuBench 2.0 - Optical Flow" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101945.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Compute: Folding @ Home Single Precision" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101946.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Compute: Geekbench 4 - GPU Compute - Total Score" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101947.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The breakdown of the GB4 subscores seems to reveal a similar uplift <a href=#>like we spotted with the Titan V</a>, which had scored in excess of 509,000 points. We'll have to investigate further but Turing and Volta are clearly accelerating some of these workloads beyond what was capable in Pascal and Maxwell.</p><p><img alt="Synthetic: TessMark, Image Set 4, 64x Tessellation" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101948.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Given that TU106 has 75% of the hardware resources of TU104, the tessellation performance is in line with expectrations. For reference, we noted earlier that the Titan V scored 703 while the Titan Xp scored 604.</p><p><img alt="Synthetic: Beyond3D Suite - Pixel Fillrate" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101973.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Synthetic: Beyond3D Suite - Integer Texture Fillrate (INT8)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph13431/101974.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH50gJJqZqeumZm2onnGnp2oqpOaerPA12ZpaW9gYrOwwc2dnKurXZqxqsDIqKVmqpWrtqbDjmpq</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. Â© 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>